import pandas as pd
import os

def charger_donnees_crime():
    # Construction du chemin absolu vers le fichier de donn√©es (../../TP1/crime_reports_broken.csv)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    nom_fichier = os.path.join(base_dir, "..", "..", "TP1", "crime_reports_broken.csv")
    
    # 1. V√©rification si le fichier existe
    if not os.path.exists(nom_fichier):
        print(f"‚ùå Erreur : Le fichier '{nom_fichier}' est introuvable.")
        return None
    
    try:
        # 2. Chargement du fichier
        # On utilise low_memory=False pour √©viter les avertissements sur les colonnes mixtes
        df = pd.read_csv(nom_fichier, low_memory=False)
        
        print(f"‚úÖ Chargement r√©ussi : {nom_fichier}")
        print(f"üìä Taille du jeu de donn√©es : {df.shape[0]} lignes et {df.shape[1]} colonnes\n")
        
        # 3. Affichage des premi√®res lignes pour v√©rifier le contenu
        print("--- Aper√ßu des donn√©es ---")
        print(df.head())
        
        # 4. Analyse rapide des types de colonnes
        print("\n--- Infos colonnes ---")
        print(df.info())

        # 5. Analyse des valeurs manquantes
        print("\n--- Valeurs manquantes par colonne ---")
        print(df.isnull().sum())

        # 6. Analyse des doublons
        print("\n--- Doublons ---")
        nb_doublons = df.duplicated().sum()
        print(f"Nombre de lignes compl√®tement dupliqu√©es : {nb_doublons}")

        # 7. Analyse de la coh√©rence (Exemple: Colonne 'Category')
        if 'Crime' in df.columns:
            print("\n--- Valeurs uniques pour 'Crime' (Aper√ßu) ---")
            print(df['Crime'].unique())
            print(f"Nombre de valeurs uniques : {df['Crime'].nunique()}")

        # 8. V√©rification du format des dates
        # On essaie de convertir la colonne 'Crime Date Time' en datetime et on compte les √©checs
        col_date = 'Crime Date Time'
        if col_date in df.columns:
            print(f"\n--- V√©rification des dates ({col_date}) ---")
            # tentative de conversion avec format explicite pour √©viter le warning
            fmt = '%m/%d/%Y %H:%M'
            dates_invalides = pd.to_datetime(df[col_date], format=fmt, errors='coerce').isna().sum() - df[col_date].isna().sum()
            print(f"Format de date invalide (non convertible) : {dates_invalides}")
        
        return df
        
    except Exception as e:
        print(f"üí• Une erreur est survenue : {e}")
        return None

def afficher_dictionnaire():
    meta_donnees = [
        {"Variable": "File Number", "Type": "Entier/Texte", "D√©finition": "Identifiant unique du rapport", "Exemple": "2016-02648"},
        {"Variable": "Date of Report", "Type": "Date", "D√©finition": "Date du signalement", "Exemple": "04/21/2016..."},
        {"Variable": "Crime Date Time", "Type": "Date/Heure", "D√©finition": "Date et heure du crime", "Exemple": "04/14/2016 18:00"},
        {"Variable": "Crime", "Type": "Texte", "D√©finition": "Type de crime", "Exemple": "Larceny from Building"},
        {"Variable": "Reporting Area", "Type": "Entier", "D√©finition": "Code zone de rapport", "Exemple": "504"},
        {"Variable": "Neighborhood", "Type": "Texte", "D√©finition": "Quartier", "Exemple": "Cambridgeport"},
        {"Variable": "Location", "Type": "Texte", "D√©finition": "Adresse approximative", "Exemple": "800 Block of..."}
    ]
    
    print("\n--- Dictionnaire des Donn√©es ---")
    df_meta = pd.DataFrame(meta_donnees)
    # On ajuste l'affichage pour bien voir tout le tableau
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    pd.set_option('display.max_colwidth', None)
    print(df_meta)
    print("-" * 50)

# --- Fonctions d'indicateurs de qualit√© ---

def indicateur_completude(df, colonnes):
    """Calcule le % de valeurs non nulles pour une liste de colonnes."""
    resultats = {}
    for col in colonnes:
        if col in df.columns:
            taux = (1 - df[col].isnull().mean()) * 100
            resultats[col] = taux
        else:
            resultats[col] = 0.0
    return pd.Series(resultats)

def indicateur_unicite(df, colonne):
    """Calcule le % de valeurs uniques (proportion par rapport au total)."""
    if colonne not in df.columns: return 0.0
    return (df[colonne].nunique() / len(df)) * 100

def indicateur_doublons(df):
    """Calcule le % de lignes strictement identiques."""
    return (df.duplicated().sum() / len(df)) * 100

def indicateur_date_valide(df, colonne):
    """Calcule le % de dates parsables."""
    if colonne not in df.columns: return 0.0
    
    # Format sp√©cifique pour 'Date of Report' et 'Crime Date Time'
    fmt = None
    if colonne == 'Date of Report':
        fmt = '%m/%d/%Y %I:%M:%S %p'
    elif colonne == 'Crime Date Time':
        fmt = '%m/%d/%Y %H:%M'
        
    # On force la conversion
    # Si fmt est fourni, c'est plus rapide et sans warning. Sinon on tente 'mixed'
    if fmt:
        dates_valides = pd.to_datetime(df[colonne], format=fmt, errors='coerce').notna().sum()
    else:
        dates_valides = pd.to_datetime(df[colonne], errors='coerce').notna().sum()
        
    return (dates_valides / len(df)) * 100

def indicateur_coherence_temporelle(df, col_report, col_crime):
    """Calcule le % de lignes o√π Date of Report >= Crime Date Time."""
    if col_report not in df.columns or col_crime not in df.columns: return 0.0
    
    # Formats sp√©cifiques connus
    fmt_report = '%m/%d/%Y %I:%M:%S %p'
    fmt_crime = '%m/%d/%Y %H:%M'
    
    dt_report = pd.to_datetime(df[col_report], format=fmt_report, errors='coerce')
    dt_crime = pd.to_datetime(df[col_crime], format=fmt_crime, errors='coerce')
    
    # On ne garde que les lignes o√π les deux dates sont valides
    valid_mask = dt_report.notna() & dt_crime.notna()
    if valid_mask.sum() == 0: return 0.0
    
    # Coh√©rent si Report >= Crime
    nb_coherents = (dt_report[valid_mask] >= dt_crime[valid_mask]).sum()
    
    return (nb_coherents / len(df)) * 100

def indicateur_conformite_area(df, colonne):
    """Calcule le % de valeurs num√©riques dans Reporting Area."""
    if colonne not in df.columns: return 0.0
    # On essaie de convertir en num√©rique
    conformes = pd.to_numeric(df[colonne], errors='coerce').notna().sum()
    return (conformes / len(df)) * 100

def auditer_qualite(df):
    """Fonction principale regroupant les indicateurs."""
    print("\nüìä --- AUDIT DE QUALIT√â --- üìä")
    
    stats = {}
    
    # 1. Compl√©tude
    completude = indicateur_completude(df, ['File Number', 'Crime', 'Neighborhood'])
    for col, val in completude.items():
        stats[f"Compl√©tude [{col}]"] = val
        
    # 2. Unicit√©
    stats["Unicit√© [File Number]"] = indicateur_unicite(df, 'File Number')
    
    # 3. Doublons
    stats["Taux Doublons Exacts"] = indicateur_doublons(df)
    
    # 4. Validit√© Dates
    stats["Validit√© Date [Date of Report]"] = indicateur_date_valide(df, 'Date of Report')
    
    # 5. Coh√©rence Temporelle
    stats["Coh√©rence Temporelle (Report >= Crime)"] = indicateur_coherence_temporelle(df, 'Date of Report', 'Crime Date Time')
    
    # 6. Conformit√© Reporting Area
    stats["Conformit√© [Reporting Area]"] = indicateur_conformite_area(df, 'Reporting Area')
    
    # Affichage avec seuils
    seuils = {
        "Compl√©tude": 95.0, # Doit √™tre >
        "Unicit√© [File Number]": 100.0, # Doit √™tre proche de
        "Taux Doublons Exacts": 0.0, # Doit √™tre proches de 0 (attention logique inverse)
        "Validit√© Date": 95.0, 
        "Coh√©rence": 98.0,
        "Conformit√©": 95.0
    }
    
    resultats_series = pd.Series(stats)
    
    for indicateur, valeur in stats.items():
        status = "‚úÖ"
        # Logique simplifi√©e de seuil (adaptable)
        if "Doublons" in indicateur:
            if valeur > 0: status = "‚ùå (> 0%)"
        else:
            if valeur < 95.0: status = "‚ùå (< 95%)" # Seuil g√©n√©rique 95% pour l'exemple
            
        print(f"{indicateur:<40} : {valeur:.2f}% {status}")
        
    return resultats_series

# --- Fonctions de Nettoyage et Enrichissement ---

VALID_NEIGHBORHOODS = {
    "Cambridgeport",
    "East Cambridge",
    "Mid-Cambridge",
    "North Cambridge",
    "Riverside",
    "Area 4",
    "West Cambridge",
    "Peabody",
    "Inman/Harrington",
    "Highlands",
    "Agassiz",
    "MIT",
    "Strawberry Hill",
}

def nettoyer_donnees(df):
    """Nettoie le dataset selon les r√®gles m√©tier."""
    print("\nüßπ --- NETTOYAGE DES DONN√âES --- üßπ")
    df_clean = df.copy()
    initial_len = len(df_clean)
    
    # 1. Doublons
    # Doublons exacts
    df_clean = df_clean.drop_duplicates()
    print(f"- Doublons exacts supprim√©s : {initial_len - len(df_clean)}")
    
    # Unicit√© ID (File Number) - on garde le premier
    len_before = len(df_clean)
    if 'File Number' in df_clean.columns:
        df_clean = df_clean.drop_duplicates(subset=['File Number'], keep='first')
    print(f"- Doublons d'ID supprim√©s   : {len_before - len(df_clean)}")
    
    # 2. Crime null
    if 'Crime' in df_clean.columns:
        len_before = len(df_clean)
        df_clean = df_clean.dropna(subset=['Crime'])
        print(f"- Lignes 'Crime' null suppr : {len_before - len(df_clean)}")

    # 3. Dates
    fmt_report = '%m/%d/%Y %I:%M:%S %p'
    fmt_crime = '%m/%d/%Y %H:%M'
    
    # Conversion et suppression des invalides
    len_before = len(df_clean)
    if 'Date of Report' in df_clean.columns:
        df_clean['Date of Report'] = pd.to_datetime(df_clean['Date of Report'], format=fmt_report, errors='coerce')
        df_clean = df_clean.dropna(subset=['Date of Report'])
        
    if 'Crime Date Time' in df_clean.columns:
        df_clean['Crime Date Time'] = pd.to_datetime(df_clean['Crime Date Time'], format=fmt_crime, errors='coerce')
        df_clean = df_clean.dropna(subset=['Crime Date Time'])
    print(f"- Dates invalides suppr     : {len_before - len(df_clean)}")
    
    # Incoh√©rence temporelle (Report < Crime)
    len_before = len(df_clean)
    if 'Date of Report' in df_clean.columns and 'Crime Date Time' in df_clean.columns:
        df_clean = df_clean[df_clean['Date of Report'] >= df_clean['Crime Date Time']]
    print(f"- Incoh√©rences temp. suppr  : {len_before - len(df_clean)}")

    # 4. Reporting Area invalide
    if 'Reporting Area' in df_clean.columns:
        len_before = len(df_clean)
        # On force en num√©rique, les erreurs deviennent NaN, puis on drop
        df_clean['Reporting Area'] = pd.to_numeric(df_clean['Reporting Area'], errors='coerce')
        df_clean = df_clean.dropna(subset=['Reporting Area'])
        # On cast en int pour √™tre propre
        df_clean['Reporting Area'] = df_clean['Reporting Area'].astype(int)
        print(f"- Reporting Area invalides  : {len_before - len(df_clean)}")

    # 5. Neighborhood invalide
    if 'Neighborhood' in df_clean.columns:
        len_before = len(df_clean)
        df_clean = df_clean[df_clean['Neighborhood'].isin(VALID_NEIGHBORHOODS)]
        print(f"- Neighborhood invalides    : {len_before - len(df_clean)}")

    print(f"Assignation finale : {len(df_clean)} lignes (Total supprim√© : {initial_len - len(df_clean)})")
    return df_clean

def enrichir_donnees(df):
    """Ajoute des colonnes d√©riv√©es."""
    print("\n‚ú® --- ENRICHISSEMENT --- ‚ú®")
    df_enrich = df.copy()
    
    # 1. Reporting Area Group
    if 'Reporting Area' in df_enrich.columns:
        # Groupe de centaines (ex: 602 -> 6)
        # Attention, Reporting Area est int maintenant
        df_enrich['reporting_area_group'] = df_enrich['Reporting Area'] // 100
        
        # Validation
        valeurs_aberrantes = df_enrich[df_enrich['reporting_area_group'] < 0]
        if not valeurs_aberrantes.empty:
            print(f"‚ö†Ô∏è Attention : {len(valeurs_aberrantes)} valeurs n√©gatives d√©tect√©es dans le groupe.")
            # On pourrait d√©cider de les supprimer ou de prendre la valeur absolue.
            # Pour l'exercice, on filtre.
            df_enrich = df_enrich[df_enrich['reporting_area_group'] >= 0]
            
        print("Colonnes ajout√©es : ['reporting_area_group']")
        
    return df_enrich

if __name__ == "__main__":
    # 0. Afficher le dictionnaire des donn√©es
    afficher_dictionnaire()

    # 1. Charger et analyser les donn√©es
    data = charger_donnees_crime()
    
    if data is not None:
        # 2. Lancer l'audit complet (Avant nettoyage)
        print("\n--- AVANT NETTOYAGE ---")
        stats_avant = auditer_qualite(data)
        
        # 3. Nettoyer les donn√©es
        data_clean = nettoyer_donnees(data)
        
        # 4. Enrichir les donn√©es
        data_enriched = enrichir_donnees(data_clean)
        
        # 5. Audit final (Apr√®s nettoyage)
        print("\n--- APR√àS NETTOYAGE ---")
        stats_apres = auditer_qualite(data_enriched)
        
        # 6. Comparaison et Monitoring
        print("\nüìà --- MONITORING DE LA QUALIT√â (AVANT vs APR√àS) --- üìà")
        comparison = pd.DataFrame({
            'Avant (%)': stats_avant,
            'Apr√®s (%)': stats_apres
        })
        comparison['Evolution'] = comparison['Apr√®s (%)'] - comparison['Avant (%)']
        
        # On ajuste l'affichage
        pd.set_option('display.float_format', '{:.2f}'.format)
        print(comparison)
        
        print("\n--- √âvolutions Significatives (> 1%) ---")
        sig_changes = comparison[comparison['Evolution'].abs() > 1.0]
        if not sig_changes.empty:
            print(sig_changes[['Avant (%)', 'Apr√®s (%)', 'Evolution']])
        else:
            print("Aucune √©volution majeure d√©tect√©e.")

        # 7. Export
        # Export dans le m√™me dossier que le script (tp1-crime/tp1-crime/)
        base_dir = os.path.dirname(os.path.abspath(__file__))
        output_file = "crime_reports_clean.csv"
        output_path = os.path.join(base_dir, output_file)
        
        data_enriched.to_csv(output_path, index=False)
        print(f"\n‚úÖ Fichier nettoy√© export√© vers : {output_path}")